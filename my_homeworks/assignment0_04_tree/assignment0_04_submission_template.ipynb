{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you submit this notebook, make sure everything runs as expected in the local test cases. \n",
    "Please, paste the solution to the designed cell and do not change anything else.\n",
    "\n",
    "Also, please, leave your first and last names below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FirstName = \"Alexander\"\n",
    "LastName = \"Gerasimov\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40b231b30fc9f58984904a569710f504",
     "grade": false,
     "grade_id": "cell-ac8fc52d8a39ccb4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "def entropy(y):  \n",
    "    \"\"\"\n",
    "    Computes entropy of the provided distribution. Use log(value + eps) for numerical stability\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.array of type float with shape (n_objects, n_classes)\n",
    "        One-hot representation of class labels for corresponding subset\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Entropy of the provided subset\n",
    "    \"\"\"\n",
    "    EPS = 0.0005\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return 0.\n",
    "    \n",
    "def gini(y):\n",
    "    \"\"\"\n",
    "    Computes the Gini impurity of the provided distribution\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.array of type float with shape (n_objects, n_classes)\n",
    "        One-hot representation of class labels for corresponding subset\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Gini impurity of the provided subset\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return 0.\n",
    "    \n",
    "def variance(y):\n",
    "    \"\"\"\n",
    "    Computes the variance the provided target values subset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.array of type float with shape (n_objects, 1)\n",
    "        Target values vector\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Variance of the provided target vector\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return 0.\n",
    "\n",
    "def mad_median(y):\n",
    "    \"\"\"\n",
    "    Computes the mean absolute deviation from the median in the\n",
    "    provided target values subset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.array of type float with shape (n_objects, 1)\n",
    "        Target values vector\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Mean absolute deviation from the median in the provided vector\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return 0.\n",
    "\n",
    "\n",
    "def one_hot_encode(n_classes, y):\n",
    "    y_one_hot = np.zeros((len(y), n_classes), dtype=float)\n",
    "    y_one_hot[np.arange(len(y)), y.astype(int)[:, 0]] = 1.\n",
    "    return y_one_hot\n",
    "\n",
    "\n",
    "def one_hot_decode(y_one_hot):\n",
    "    return y_one_hot.argmax(axis=1)[:, None]\n",
    "\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    This class is provided \"as is\" and it is not mandatory to it use in your code.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_index, threshold, proba=0):\n",
    "        self.feature_index = feature_index\n",
    "        self.value = threshold\n",
    "        self.proba = proba\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "        \n",
    "        \n",
    "class DecisionTree(BaseEstimator):\n",
    "    all_criterions = {\n",
    "        'gini': (gini, True), # (criterion, classification flag)\n",
    "        'entropy': (entropy, True),\n",
    "        'variance': (variance, False),\n",
    "        'mad_median': (mad_median, False)\n",
    "    }\n",
    "\n",
    "    def __init__(self, n_classes=None, max_depth=np.inf, min_samples_split=2, \n",
    "                 criterion_name='gini', debug=False):\n",
    "\n",
    "        assert criterion_name in self.all_criterions.keys(), 'Criterion name must be on of the following: {}'.format(self.all_criterions.keys())\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.criterion_name = criterion_name\n",
    "\n",
    "        self.depth = 0\n",
    "        self.root = None # Use the Node class to initialize it later\n",
    "        self.debug = debug\n",
    "\n",
    "        \n",
    "        \n",
    "    def make_split(self, feature_index, threshold, X_subset, y_subset):\n",
    "        \"\"\"\n",
    "        Makes split of the provided data subset and target values using provided feature and threshold\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        feature_index : int\n",
    "            Index of feature to make split with\n",
    "\n",
    "        threshold : float\n",
    "            Threshold value to perform split\n",
    "\n",
    "        X_subset : np.array of type float with shape (n_objects, n_features)\n",
    "            Feature matrix representing the selected subset\n",
    "\n",
    "        y_subset : np.array of type float with shape (n_objects, n_classes) in classification \n",
    "                   (n_objects, 1) in regression \n",
    "            One-hot representation of class labels for corresponding subset\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        (X_left, y_left) : tuple of np.arrays of same type as input X_subset and y_subset\n",
    "            Part of the providev subset where selected feature x^j < threshold\n",
    "        (X_right, y_right) : tuple of np.arrays of same type as input X_subset and y_subset\n",
    "            Part of the providev subset where selected feature x^j >= threshold\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        return (X_left, y_left), (X_right, y_right)\n",
    "    \n",
    "    def make_split_only_y(self, feature_index, threshold, X_subset, y_subset):\n",
    "        \"\"\"\n",
    "        Split only target values into two subsets with specified feature and threshold\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        feature_index : int\n",
    "            Index of feature to make split with\n",
    "\n",
    "        threshold : float\n",
    "            Threshold value to perform split\n",
    "\n",
    "        X_subset : np.array of type float with shape (n_objects, n_features)\n",
    "            Feature matrix representing the selected subset\n",
    "\n",
    "        y_subset : np.array of type float with shape (n_objects, n_classes) in classification \n",
    "                   (n_objects, 1) in regression \n",
    "            One-hot representation of class labels for corresponding subset\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        y_left : np.array of type float with shape (n_objects_left, n_classes) in classification \n",
    "                   (n_objects, 1) in regression \n",
    "            Part of the provided subset where selected feature x^j < threshold\n",
    "\n",
    "        y_right : np.array of type float with shape (n_objects_right, n_classes) in classification \n",
    "                   (n_objects, 1) in regression \n",
    "            Part of the provided subset where selected feature x^j >= threshold\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        return y_left, y_right\n",
    "\n",
    "    def choose_best_split(self, X_subset, y_subset):\n",
    "        \"\"\"\n",
    "        Greedily select the best feature and best threshold w.r.t. selected criterion\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X_subset : np.array of type float with shape (n_objects, n_features)\n",
    "            Feature matrix representing the selected subset\n",
    "\n",
    "        y_subset : np.array of type float with shape (n_objects, n_classes) in classification \n",
    "                   (n_objects, 1) in regression \n",
    "            One-hot representation of class labels or target values for corresponding subset\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        feature_index : int\n",
    "            Index of feature to make split with\n",
    "\n",
    "        threshold : float\n",
    "            Threshold value to perform split\n",
    "\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        return feature_index, threshold\n",
    "    \n",
    "    def make_tree(self, X_subset, y_subset):\n",
    "        \"\"\"\n",
    "        Recursively builds the tree\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X_subset : np.array of type float with shape (n_objects, n_features)\n",
    "            Feature matrix representing the selected subset\n",
    "\n",
    "        y_subset : np.array of type float with shape (n_objects, n_classes) in classification \n",
    "                   (n_objects, 1) in regression \n",
    "            One-hot representation of class labels or target values for corresponding subset\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        root_node : Node class instance\n",
    "            Node of the root of the fitted tree\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        return new_node\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the model from scratch using the provided data\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array of type float with shape (n_objects, n_features)\n",
    "            Feature matrix representing the data to train on\n",
    "\n",
    "        y : np.array of type int with shape (n_objects, 1) in classification \n",
    "                   of type float with shape (n_objects, 1) in regression \n",
    "            Column vector of class labels in classification or target values in regression\n",
    "        \n",
    "        \"\"\"\n",
    "        assert len(y.shape) == 2 and len(y) == len(X), 'Wrong y shape'\n",
    "        self.criterion, self.classification = self.all_criterions[self.criterion_name]\n",
    "        if self.classification:\n",
    "            if self.n_classes is None:\n",
    "                self.n_classes = len(np.unique(y))\n",
    "            y = one_hot_encode(self.n_classes, y)\n",
    "\n",
    "        self.root = self.make_tree(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the target value or class label  the model from scratch using the provided data\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array of type float with shape (n_objects, n_features)\n",
    "            Feature matrix representing the data the predictions should be provided for\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_predicted : np.array of type int with shape (n_objects, 1) in classification \n",
    "                   (n_objects, 1) in regression \n",
    "            Column vector of class labels in classification or target values in regression\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        return y_predicted\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Only for classification\n",
    "        Predict the class probabilities using the provided data\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.array of type float with shape (n_objects, n_features)\n",
    "            Feature matrix representing the data the predictions should be provided for\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_predicted_probs : np.array of type float with shape (n_objects, n_classes)\n",
    "            Probabilities of each class for the provided objects\n",
    "        \n",
    "        \"\"\"\n",
    "        assert self.classification, 'Available only for classification problem'\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        return y_predicted_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 0: Initialization (0.01 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3dee5ee83e0f63188671f08b57d70804",
     "grade": true,
     "grade_id": "cell-3473b7b6ffd64d07",
     "locked": true,
     "points": 0.01,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# do not change this cell\n",
    "import numpy as np\n",
    "import unittest\n",
    "import sys\n",
    "import io\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing, load_digits\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits_data = load_digits(n_class=2).data\n",
    "digits_target = load_digits(n_class=2).target[:, None]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Make splits loops (0.1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48b2963c650791df41dfbd190ed247fd",
     "grade": true,
     "grade_id": "cell-e3503c286039ec55",
     "locked": true,
     "points": 0.09,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_left' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7b/cdzljzwj56x_f21dmtsrbpfr0000gn/T/ipykernel_43825/3661514711.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclass_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mX_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_r\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mflag_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_l\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/7b/cdzljzwj56x_f21dmtsrbpfr0000gn/T/ipykernel_43825/3507564436.py\u001b[0m in \u001b[0;36mmake_split\u001b[0;34m(self, feature_index, threshold, X_subset, y_subset)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_split_only_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_left' is not defined"
     ]
    }
   ],
   "source": [
    "X = np.ones((4, 5), dtype=float) * np.arange(4)[:, None]\n",
    "y = np.arange(4)[:, None] + np.asarray([0.2, -0.3, 0.1, 0.4])[:, None]\n",
    "class_estimator = DecisionTree(max_depth=5, criterion_name='gini')\n",
    "\n",
    "(X_l, y_l), (X_r, y_r) = class_estimator.make_split(1, 1., X, y)\n",
    "\n",
    "flag_X = np.array_equal(X[:1], X_l) and np.array_equal(X[1:], X_r) \n",
    "flag_y = np.array_equal(y[:1], y_l) and np.array_equal(y[1:], y_r)\n",
    "assert flag_X and flag_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Gini accuracy (0.2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a2a5e274d8d866e1242a339a7751642",
     "grade": true,
     "grade_id": "cell-e2c4124a6f815118",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7b/cdzljzwj56x_f21dmtsrbpfr0000gn/T/ipykernel_43825/690562759.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclass_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclass_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maccuracy_gini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;36m0.96\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0maccuracy_gini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "class_estimator = DecisionTree(max_depth=5, criterion_name='gini')\n",
    "class_estimator.fit(X_train, y_train)\n",
    "ans = class_estimator.predict(X_test)\n",
    "accuracy_gini = accuracy_score(y_test, ans)\n",
    "assert 0.96 < accuracy_gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: Entropy accuracy (0.2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3b167fd8a4950ffe1f1b8f691ab7f91",
     "grade": true,
     "grade_id": "cell-69473387a23d8dff",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7b/cdzljzwj56x_f21dmtsrbpfr0000gn/T/ipykernel_43825/2715076682.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclass_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'entropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclass_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;36m0.96\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "class_estimator = DecisionTree(max_depth=5, criterion_name='entropy')\n",
    "class_estimator.fit(X_train, y_train)\n",
    "ans = class_estimator.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, ans)\n",
    "assert 0.96 < accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4: Entropy probabilities (0.2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ea5402e3fc351fe4bdc17dc7d48b591",
     "grade": true,
     "grade_id": "cell-e5f59af66e6c111b",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7b/cdzljzwj56x_f21dmtsrbpfr0000gn/T/ipykernel_43825/2358880895.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclass_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'entropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclass_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.48611111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.51388889\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "class_estimator = DecisionTree(max_depth=10, criterion_name='entropy')\n",
    "class_estimator.fit(X_train, y_train)\n",
    "ans = class_estimator.predict(X_test)\n",
    "reference = np.array([0.48611111, 0.51388889])\n",
    "assert np.abs(np.sum(class_estimator.predict_proba(X_test).mean(axis=0) - reference)) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 5: MSE mad_median (0.15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "740411f734d1c9841d5fcc124eb129d1",
     "grade": true,
     "grade_id": "cell-1a9c1e3609ed9aab",
     "locked": true,
     "points": 0.15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_node' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7b/cdzljzwj56x_f21dmtsrbpfr0000gn/T/ipykernel_43825/484866156.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mregressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mad_median'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRy_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mpredictions_mad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRy_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_mad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/7b/cdzljzwj56x_f21dmtsrbpfr0000gn/T/ipykernel_43825/3507564436.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/7b/cdzljzwj56x_f21dmtsrbpfr0000gn/T/ipykernel_43825/3507564436.py\u001b[0m in \u001b[0;36mmake_tree\u001b[0;34m(self, X_subset, y_subset)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_node' is not defined"
     ]
    }
   ],
   "source": [
    "housing = fetch_california_housing()\n",
    "random_indices = np.random.choice(np.arange(len(housing.data)), 500)\n",
    "\n",
    "regr_data = housing.data[random_indices]\n",
    "regr_target = housing.target[random_indices, None]\n",
    "RX_train, RX_test, Ry_train, Ry_test = train_test_split(regr_data, regr_target, test_size=0.2, random_state=42)\n",
    "\n",
    "regressor = DecisionTree(max_depth=8, criterion_name='mad_median')\n",
    "regressor.fit(RX_train, Ry_train)\n",
    "predictions_mad = regressor.predict(RX_test)\n",
    "mse = mean_squared_error(Ry_test, predictions_mad)\n",
    "assert 0.4 < mse < 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 6: MSE Variance (0.15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8ae6da572b6c3a76405ebfa4b9f4fd6",
     "grade": true,
     "grade_id": "cell-1ddb0377b6c68deb",
     "locked": true,
     "points": 0.15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_node' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7b/cdzljzwj56x_f21dmtsrbpfr0000gn/T/ipykernel_43825/1093317615.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mregressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'variance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRy_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mpredictions_mad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRy_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_mad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/7b/cdzljzwj56x_f21dmtsrbpfr0000gn/T/ipykernel_43825/3507564436.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/7b/cdzljzwj56x_f21dmtsrbpfr0000gn/T/ipykernel_43825/3507564436.py\u001b[0m in \u001b[0;36mmake_tree\u001b[0;34m(self, X_subset, y_subset)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_node' is not defined"
     ]
    }
   ],
   "source": [
    "housing = fetch_california_housing()\n",
    "random_indices = np.random.choice(np.arange(len(housing.data)), 500)\n",
    "\n",
    "regr_data = housing.data[random_indices]\n",
    "regr_target = housing.target[random_indices, None]\n",
    "RX_train, RX_test, Ry_train, Ry_test = train_test_split(regr_data, regr_target, test_size=0.2, random_state=42)\n",
    "\n",
    "regressor = DecisionTree(max_depth=8, criterion_name='variance')\n",
    "regressor.fit(RX_train, Ry_train)\n",
    "predictions_mad = regressor.predict(RX_test)\n",
    "mse = mean_squared_error(Ry_test, predictions_mad)\n",
    "assert 0.5 < mse < 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
